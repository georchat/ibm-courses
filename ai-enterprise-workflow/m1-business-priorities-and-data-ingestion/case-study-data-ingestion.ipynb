{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "![ibm cloud logo](./images/ibm-cloud.png)\n\n# Case Study - Data ingestion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The goal of this case study is to put into practice the important concepts from module 1.  We will go through the basic process that begins with refining the business opportunity and ensuring that it is articulated using a scientific thought process.\n\nThe business opportunity and case study was first mentioned in Unit 2 of module 1 and like the AAVIAL company itself these data were created for learning purposes.  We will be using the AAVAIL example as a basis for this case study.  [Watch the video again](https://vimeo.com/348708995) if you need a refresher.  You will be gathering data from several provided sources, staging it for quality assurance and saving it in a target destination that is most appropriate.\n\nWatch the video to review the important concepts from the units you just covered and to see an overview of the objectives for this case study."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\n        <iframe\n            width=\"600\"\n            height=\"400\"\n            src=\"https://player.vimeo.com/video/354996550\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                        "text/plain": "<IPython.lib.display.IFrame at 0x7f364428acc0>"
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from IPython.display import IFrame\nIFrame('https://player.vimeo.com/video/354996550', width=600,height=400)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Case study overall objectives\n\n1. Gather all relevant data from the sources of provided data\n2. Implement several checks for quality assurance \n3. Take the initial steps towards automation of the ingestion pipeline\n\n## Getting started\n\nDownload this notebook and open it locally using a Jupyter server. Alternatively you may use Watson Studio.  To make using Watson Studio easier we have provided a zip archive file containing the files needed to complete this case study in Watson Studio. See the [Getting started with Watson Studio](m1-u5-5-watson-studio.rst) page.\n\n**You will need the following files to complete this case study**\n\n* [m1-u6-case-study.ipynb](m1-u6-case-study.ipynb)\n* [m1-u6-case-study-solution.ipynb](./notebooks/m1-u6-case-study-solution.ipynb)\n* [aavail-customers.db](./data/aavail-customers.db)\n* [aavail-steams.csv](./data/aavail-streams.csv)\n\n1. Fill in all of the places in this notebook marked with ***YOUR CODE HERE*** or ***YOUR ANSWER HERE***\n2. When you have finished the case study there will be a short quiz\n\nYou may review the rest of this content as part of the notebook, but once you are ready to get started be ensure that you are working with a *live* version either as part of Watson Studio or locally."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Make Notebook Run in Watson Studio"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "# START CODE BLOCK\n# cos2file - takes an object from Cloud Object Storage and writes it to file on container file system.\n# Uses the IBM project_lib library.\n# See https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/project-lib-python.html\n# Arguments:\n# p: project object defined in project token\n# data_path: the directory to write the file\n# filename: name of the file in COS\n\nimport os\ndef cos2file(p,data_path,filename):\n    data_dir = p.project_context.home + data_path\n    if not os.path.exists(data_dir):\n        os.makedirs(data_dir)\n    open( data_dir + '/' + filename, 'wb').write(p.get_file(filename).read())\n\n# file2cos - takes file on container file system and writes it to an object in Cloud Object Storage.\n# Uses the IBM project_lib library.\n# See https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/project-lib-python.html\n# Arguments:\n# p: prooject object defined in project token\n# data_path: the directory to read the file from\n# filename: name of the file on container file system\n\nimport os\ndef file2cos(p,data_path,filename):\n    data_dir = p.project_context.home + data_path\n    path_to_file = data_dir + '/' + filename\n    if os.path.exists(path_to_file):\n        file_object = open(path_to_file, 'rb')\n        p.save_data(filename, file_object, set_project_asset=True, overwrite=True)\n    else:\n        print(\"file2cos error: File not found\")\n# END CODE BLOCK"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Create Data Directory"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "cos2file(project, '/data', 'aavail-customers.db')\ncos2file(project, '/data', 'aavail-streams.csv')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data Sources\n\nThe data you will be sourcing from is contained in two sources.\n\n1. A database ([SQLite](https://www.sqlite.org/index.html)) of `customer` data\n2. A [CSV file](https://en.wikipedia.org/wiki/Comma-separated_values) of `stream` level data\n\n   >You will create a simple data pipeline that\n   (1) simplifies the data for future analysis\n   (2) performs quality assurance checks.\n\nThe process of building *the data ingestion pipeline* entails extracting data, transforming it, and loading it into an appropriate data storage technology.  When constructing a pipeline it is important to keep in mind that they generally process data in batches.  For example, data may be compiled during the day and the batch could be processed during the night.  The data pipeline may also be optimized to execute as a streaming computation (i.e., every event is handled as it occurs)."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## PART 1: Gathering the data\n\nThe following is an [Entity Relationship Diagram (ERD)](https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model) that details the tables and contents of the database.\n\n<img src=\"./images/aavail-schema.svg\" alt=\"customer database schema\" style=\"width: 600px;\"/>"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "## all the imports you will need for this case study\nimport os\nimport pandas as pd\nimport numpy as np\nimport sqlite3"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Much of the data exist in a database.  You can connect to is using the `sqlite3` Python package with the function shown below.  Note that is is good practice to wrap your connect functions in a [try-except statement](https://docs.python.org/3/tutorial/errors.html) to cleanly handle exceptions."
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "def connect_db(file_path):\n    try:\n        conn = sqlite3.connect(file_path)\n        print(\"...successfully connected to db\\n\")\n    except Error as e:\n        print(\"...unsuccessful connection\\n\",e)\n    \n    return(conn)"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "...successfully connected to db\n\n['CUSTOMER', 'INVOICE', 'INVOICE_ITEM', 'COUNTRY']\n"
                }
            ],
            "source": "## make the connection to the database\nconn = connect_db('../data/aavail-customers.db')\n\n## print the table names\ntables = [t[0] for t in conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")]\nprint(tables)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### QUESTION 1:\n\n**extract the relevant data from the DB**\n\nQuery the database and extract the following data into a [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html).\n \n* Customer ID (integer)\n* Last name\n* First name\n* DOB\n* City\n* State\n* Country (the name NOT the country_id)\n* Gender\n\nRemember that that SQL is case-insensitive, but it is traditional to use ALL CAPS for SQL keywords. It is also a convention to end SQL statements with a semi-colon.  \n\n#### Resources\n\n* [W3 schools SQL tutorial](https://www.w3schools.com/sql)\n* [W3 schools SQL joins](https://www.w3schools.com/sql/sql_join.asp)"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>last_name</th>\n      <th>first_name</th>\n      <th>DOB</th>\n      <th>city</th>\n      <th>state</th>\n      <th>country_name</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Todd</td>\n      <td>Kasen</td>\n      <td>07/30/98</td>\n      <td>Rock Hill</td>\n      <td>South Carolina</td>\n      <td>united_states</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Garza</td>\n      <td>Ensley</td>\n      <td>04/12/89</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Carey</td>\n      <td>Lillian</td>\n      <td>09/12/97</td>\n      <td>Auburn</td>\n      <td>Alabama</td>\n      <td>united_states</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Christensen</td>\n      <td>Beau</td>\n      <td>01/28/99</td>\n      <td>Hempstead</td>\n      <td>New York</td>\n      <td>united_states</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Gibson</td>\n      <td>Ernesto</td>\n      <td>03/23/98</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>m</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id    last_name first_name       DOB       city           state  \\\n0            1         Todd      Kasen  07/30/98  Rock Hill  South Carolina   \n1            2        Garza     Ensley  04/12/89  singapore            None   \n2            3        Carey    Lillian  09/12/97     Auburn         Alabama   \n3            4  Christensen       Beau  01/28/99  Hempstead        New York   \n4            5       Gibson    Ernesto  03/23/98  singapore            None   \n\n    country_name gender  \n0  united_states      m  \n1      singapore      f  \n2  united_states      f  \n3  united_states      m  \n4      singapore      m  "
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "query = \"\"\"SELECT \n            CUSTOMER.customer_id, \n            CUSTOMER.last_name,\n            CUSTOMER.first_name,\n            CUSTOMER.DOB,\n            CUSTOMER.city, \n            CUSTOMER.state, \n            COUNTRY.country_name, \n            CUSTOMER.gender\n            FROM CUSTOMER\n            LEFT JOIN COUNTRY \n            ON CUSTOMER.country_id = COUNTRY.country_id;\"\"\"\n\ndf_customers = pd.DataFrame([row for row in conn.execute(query)], \n                            columns=[\"customer_id\", \"last_name\", \"first_name\", \"DOB\", \"city\", \"state\", \"country_name\", \"gender\"])\ndf_customers.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1007 entries, 0 to 1006\nData columns (total 8 columns):\ncustomer_id     1007 non-null int64\nlast_name       1007 non-null object\nfirst_name      1007 non-null object\nDOB             1007 non-null object\ncity            1007 non-null object\nstate           703 non-null object\ncountry_name    1007 non-null object\ngender          1007 non-null object\ndtypes: int64(1), object(7)\nmemory usage: 63.0+ KB\n"
                }
            ],
            "source": "df_customers.info()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The customers dataset has features type `int64` and `object`. Feature `state` contains also `NaN`."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### QUESTION 2:\n\n**Extract the relevant data from the CSV file**\n\nFor each ```customer_id``` determine if a customer has stopped their subscription or not and save it in a dictionary or another data container."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>stream_id</th>\n      <th>date</th>\n      <th>subscription_stopped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1356</td>\n      <td>2018-12-01</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1540</td>\n      <td>2018-12-04</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1395</td>\n      <td>2018-12-11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1255</td>\n      <td>2018-12-22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1697</td>\n      <td>2018-12-23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id  stream_id        date  subscription_stopped\n0            1       1356  2018-12-01                     0\n1            1       1540  2018-12-04                     0\n2            1       1395  2018-12-11                     0\n3            1       1255  2018-12-22                     0\n4            1       1697  2018-12-23                     0"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_streams = pd.read_csv('../data/aavail-streams.csv')\ndf_streams.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 19032 entries, 0 to 19031\nData columns (total 4 columns):\ncustomer_id             19032 non-null int64\nstream_id               19032 non-null int64\ndate                    19032 non-null object\nsubscription_stopped    19032 non-null int64\ndtypes: int64(3), object(1)\nmemory usage: 594.8+ KB\n"
                }
            ],
            "source": "df_streams.info()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The streams dataset doesn't contain any `NaN` values."
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>stream_id</th>\n      <th>subscription_stopped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>19032.000000</td>\n      <td>19032.000000</td>\n      <td>19032.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>500.478142</td>\n      <td>1387.988703</td>\n      <td>0.014765</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>290.447934</td>\n      <td>224.176814</td>\n      <td>0.120613</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>248.000000</td>\n      <td>1195.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>497.000000</td>\n      <td>1389.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>753.000000</td>\n      <td>1584.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1000.000000</td>\n      <td>1776.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "        customer_id     stream_id  subscription_stopped\ncount  19032.000000  19032.000000          19032.000000\nmean     500.478142   1387.988703              0.014765\nstd      290.447934    224.176814              0.120613\nmin        1.000000   1000.000000              0.000000\n25%      248.000000   1195.000000              0.000000\n50%      497.000000   1389.000000              0.000000\n75%      753.000000   1584.000000              0.000000\nmax     1000.000000   1776.000000              1.000000"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_streams.describe()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The feature `subscription_stopped` is of type `int64` where the max value is 1 and the min is 0. I assume 1 represents those `streams_id` per `customer_id` that were stopped."
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>stream_id</th>\n      <th>date</th>\n      <th>subscription_stopped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37</th>\n      <td>3</td>\n      <td>1689</td>\n      <td>2019-01-24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>3</td>\n      <td>1414</td>\n      <td>2019-01-27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>3</td>\n      <td>1157</td>\n      <td>2019-01-27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>3</td>\n      <td>1401</td>\n      <td>2019-02-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>3</td>\n      <td>1374</td>\n      <td>2019-02-13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>3</td>\n      <td>1143</td>\n      <td>2019-02-19</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>3</td>\n      <td>1540</td>\n      <td>2019-02-27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>3</td>\n      <td>1548</td>\n      <td>2019-03-01</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>3</td>\n      <td>1455</td>\n      <td>2019-03-09</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>3</td>\n      <td>1170</td>\n      <td>2019-03-17</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>3</td>\n      <td>1428</td>\n      <td>2019-03-24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>3</td>\n      <td>1510</td>\n      <td>2019-03-26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>3</td>\n      <td>1552</td>\n      <td>2019-03-28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>3</td>\n      <td>1617</td>\n      <td>2019-04-11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>3</td>\n      <td>1556</td>\n      <td>2019-04-14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>3</td>\n      <td>1650</td>\n      <td>2019-04-22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>3</td>\n      <td>1162</td>\n      <td>2019-05-01</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>3</td>\n      <td>1120</td>\n      <td>2019-05-02</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>3</td>\n      <td>1231</td>\n      <td>2019-05-07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>3</td>\n      <td>1354</td>\n      <td>2019-05-10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>3</td>\n      <td>1646</td>\n      <td>2019-05-11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>3</td>\n      <td>1421</td>\n      <td>2019-05-16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>3</td>\n      <td>1020</td>\n      <td>2019-05-21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>3</td>\n      <td>1319</td>\n      <td>2019-05-24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>3</td>\n      <td>1689</td>\n      <td>2019-05-30</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "    customer_id  stream_id        date  subscription_stopped\n37            3       1689  2019-01-24                     0\n38            3       1414  2019-01-27                     0\n39            3       1157  2019-01-27                     0\n40            3       1401  2019-02-12                     0\n41            3       1374  2019-02-13                     0\n42            3       1143  2019-02-19                     0\n43            3       1540  2019-02-27                     0\n44            3       1548  2019-03-01                     0\n45            3       1455  2019-03-09                     0\n46            3       1170  2019-03-17                     0\n47            3       1428  2019-03-24                     0\n48            3       1510  2019-03-26                     0\n49            3       1552  2019-03-28                     0\n50            3       1617  2019-04-11                     0\n51            3       1556  2019-04-14                     0\n52            3       1650  2019-04-22                     0\n53            3       1162  2019-05-01                     0\n54            3       1120  2019-05-02                     0\n55            3       1231  2019-05-07                     0\n56            3       1354  2019-05-10                     0\n57            3       1646  2019-05-11                     0\n58            3       1421  2019-05-16                     0\n59            3       1020  2019-05-21                     0\n60            3       1319  2019-05-24                     0\n61            3       1689  2019-05-30                     0"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_streams[df_streams.customer_id==3]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "For each customer I get the latest date and check whether the customer stopped the subscription or not."
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>stream_id</th>\n      <th>date</th>\n      <th>subscription_stopped</th>\n      <th>is_subscriber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1521</td>\n      <td>2019-03-12</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1497</td>\n      <td>2019-06-07</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1689</td>\n      <td>2019-05-30</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1140</td>\n      <td>2018-03-28</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1280</td>\n      <td>2019-05-20</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id  stream_id        date  subscription_stopped  is_subscriber\n0            1       1521  2019-03-12                     0              1\n1            2       1497  2019-06-07                     1              0\n2            3       1689  2019-05-30                     0              1\n3            4       1140  2018-03-28                     0              1\n4            5       1280  2019-05-20                     0              1"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_churns = df_streams.sort_values([\"customer_id\",\"date\"], ascending=False).groupby([\"customer_id\"]).head(1)\ndf_churns = df_churns.sort_values([\"customer_id\"]).reset_index(drop=True)\ndf_churns[\"is_subscriber\"] = np.where(df_churns.subscription_stopped == 1, 0, 1)\ndf_churns.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 5 columns):\ncustomer_id             1000 non-null int64\nstream_id               1000 non-null int64\ndate                    1000 non-null object\nsubscription_stopped    1000 non-null int64\nis_subscriber           1000 non-null int64\ndtypes: int64(4), object(1)\nmemory usage: 39.1+ KB\n"
                }
            ],
            "source": "df_churns.info()"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>stream_id</th>\n      <th>subscription_stopped</th>\n      <th>is_subscriber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>500.500000</td>\n      <td>1379.847000</td>\n      <td>0.245000</td>\n      <td>0.755000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>288.819436</td>\n      <td>224.048319</td>\n      <td>0.430302</td>\n      <td>0.430302</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1000.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>250.750000</td>\n      <td>1187.750000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>500.500000</td>\n      <td>1363.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>750.250000</td>\n      <td>1577.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1000.000000</td>\n      <td>1776.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "       customer_id    stream_id  subscription_stopped  is_subscriber\ncount  1000.000000  1000.000000           1000.000000    1000.000000\nmean    500.500000  1379.847000              0.245000       0.755000\nstd     288.819436   224.048319              0.430302       0.430302\nmin       1.000000  1000.000000              0.000000       0.000000\n25%     250.750000  1187.750000              0.000000       1.000000\n50%     500.500000  1363.000000              0.000000       1.000000\n75%     750.250000  1577.000000              0.000000       1.000000\nmax    1000.000000  1776.000000              1.000000       1.000000"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_churns.describe()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## PART 2: Checks for quality assurance\n\nSometimes it is known in advance which types of data integrity issues to expect, but other times it is during the Exploratory Data Analysis (EDA) process that these issues are identified.  After extracting data it is important to include checks for quality assurance even on the first pass through the AI workflow.  Here you will combine the data into a single structure and provide a couple checks for quality assurance.\n\n### QUESTION 3: \n\n**Implement checks for quality assurance**\n\n1. Remove any repeat customers based on ```customer_id```\n2. Remove stream data that do not have an associated ```stream_id```\n3. Check for missing values"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**1. Remove any repeat customers based on `customer_id`**"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "number of duplicates: 7\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>last_name</th>\n      <th>first_name</th>\n      <th>DOB</th>\n      <th>city</th>\n      <th>state</th>\n      <th>country_name</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000</th>\n      <td>1</td>\n      <td>Todd</td>\n      <td>Kasen</td>\n      <td>07/30/98</td>\n      <td>Rock Hill</td>\n      <td>South Carolina</td>\n      <td>united_states</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>11</td>\n      <td>Rivas</td>\n      <td>Rohan</td>\n      <td>01/23/05</td>\n      <td>Pawtucket</td>\n      <td>Rhode Island</td>\n      <td>united_states</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>21</td>\n      <td>Hickman</td>\n      <td>Claudia</td>\n      <td>06/08/81</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>31</td>\n      <td>Rubio</td>\n      <td>Dalary</td>\n      <td>07/12/00</td>\n      <td>Indio</td>\n      <td>California</td>\n      <td>united_states</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>301</td>\n      <td>Fisher</td>\n      <td>Jamie</td>\n      <td>12/31/82</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>1005</th>\n      <td>401</td>\n      <td>Hill</td>\n      <td>Brodie</td>\n      <td>11/30/98</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>801</td>\n      <td>Snow</td>\n      <td>Kora</td>\n      <td>07/23/70</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>f</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "      customer_id last_name first_name       DOB       city           state  \\\n1000            1      Todd      Kasen  07/30/98  Rock Hill  South Carolina   \n1001           11     Rivas      Rohan  01/23/05  Pawtucket    Rhode Island   \n1002           21   Hickman    Claudia  06/08/81  singapore            None   \n1003           31     Rubio     Dalary  07/12/00      Indio      California   \n1004          301    Fisher      Jamie  12/31/82  singapore            None   \n1005          401      Hill     Brodie  11/30/98  singapore            None   \n1006          801      Snow       Kora  07/23/70  singapore            None   \n\n       country_name gender  \n1000  united_states      m  \n1001  united_states      m  \n1002      singapore      f  \n1003  united_states      f  \n1004      singapore      m  \n1005      singapore      m  \n1006      singapore      f  "
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "is_duplicate = df_customers.duplicated(subset=[\"customer_id\"])\nprint(\"number of duplicates:\", len(df_customers[is_duplicate]))\ndf_customers[is_duplicate]"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "# remove the duplicate records from the customer dataset:\ndf_customers = df_customers[~is_duplicate].reset_index(drop=True)"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 8 columns):\ncustomer_id     1000 non-null int64\nlast_name       1000 non-null object\nfirst_name      1000 non-null object\nDOB             1000 non-null object\ncity            1000 non-null object\nstate           700 non-null object\ncountry_name    1000 non-null object\ngender          1000 non-null object\ndtypes: int64(1), object(7)\nmemory usage: 62.6+ KB\n"
                }
            ],
            "source": "df_customers.info()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**2. Remove stream data that do not have an associated `stream_id`**"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "number of records that do not have an associated stream id: 0\n"
                }
            ],
            "source": "print(\"number of records that do not have an associated stream id:\", df_streams[\"stream_id\"].isna().sum())\n\nis_na = df_streams[\"stream_id\"].isna()\ndf_streams = df_streams[~is_na].reset_index(drop=True)"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 19032 entries, 0 to 19031\nData columns (total 4 columns):\ncustomer_id             19032 non-null int64\nstream_id               19032 non-null int64\ndate                    19032 non-null object\nsubscription_stopped    19032 non-null int64\ndtypes: int64(3), object(1)\nmemory usage: 594.8+ KB\n"
                }
            ],
            "source": "df_streams.info()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**3. Check for missing values**"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>state</th>\n      <td>300</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>country_name</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>city</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>DOB</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>first_name</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>last_name</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>customer_id</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "              Total  Percent\nstate           300      0.3\ngender            0      0.0\ncountry_name      0      0.0\ncity              0      0.0\nDOB               0      0.0\nfirst_name        0      0.0\nlast_name         0      0.0\ncustomer_id       0      0.0"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# missing data in customers dataset\ntotal = df_customers.isnull().sum().sort_values(ascending=False)\npercent = (df_customers.isnull().sum()/df_customers.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>last_name</th>\n      <th>first_name</th>\n      <th>DOB</th>\n      <th>city</th>\n      <th>state</th>\n      <th>country_name</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Garza</td>\n      <td>Ensley</td>\n      <td>04/12/89</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Gibson</td>\n      <td>Ernesto</td>\n      <td>03/23/98</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Tate</td>\n      <td>Daxton</td>\n      <td>12/23/70</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>Ross</td>\n      <td>Romina</td>\n      <td>05/05/80</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>Torres</td>\n      <td>Zayne</td>\n      <td>10/11/74</td>\n      <td>singapore</td>\n      <td>None</td>\n      <td>singapore</td>\n      <td>m</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "    customer_id last_name first_name       DOB       city state country_name  \\\n1             2     Garza     Ensley  04/12/89  singapore  None    singapore   \n4             5    Gibson    Ernesto  03/23/98  singapore  None    singapore   \n6             7      Tate     Daxton  12/23/70  singapore  None    singapore   \n11           12      Ross     Romina  05/05/80  singapore  None    singapore   \n17           18    Torres      Zayne  10/11/74  singapore  None    singapore   \n\n   gender  \n1       f  \n4       m  \n6       m  \n11      f  \n17      m  "
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_customers[df_customers.isna().any(1)].head()"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>subscription_stopped</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>date</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>stream_id</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>customer_id</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                      Total  Percent\nsubscription_stopped      0      0.0\ndate                      0      0.0\nstream_id                 0      0.0\ncustomer_id               0      0.0"
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# missing data in streams dataset\ntotal = df_streams.isnull().sum().sort_values(ascending=False)\npercent = (df_streams.isnull().sum()/df_streams.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The stream dataset doesn't contain any NaN values."
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>stream_id</th>\n      <th>date</th>\n      <th>subscription_stopped</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "Empty DataFrame\nColumns: [customer_id, stream_id, date, subscription_stopped]\nIndex: []"
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_streams[df_streams.isna().any(1)].head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### QUESTION 4: \n\n**combine the data into a single data structure**\n\nFor this example, the two most convenient structures for this task are Pandas dataframes and NumPy arrays.  At a minimum ensure that your structure accommodates the following.\n\n1. A column for `customer_id`\n2. A column for `country`\n3. A column for ```age``` that is created from ```DOB```\n4. A column ```customer_name``` that is created from ```first_name``` and ```last_name```\n5. A column to indicate churn called ```is_subscriber```\n7. A column that indicates ```subscriber_type``` that comes from ```invoice_item```\n6. A column to indicate the total ```num_streams```\n\n#### Resources\n\n* [Python's datetime library](https://docs.python.org/3/library/datetime.html)\n* [NumPy's datetime data type](https://docs.scipy.org/doc/numpy/reference/arrays.datetime.html)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>country_name</th>\n      <th>age</th>\n      <th>customer_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>united_states</td>\n      <td>22</td>\n      <td>Kasen Todd</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>singapore</td>\n      <td>31</td>\n      <td>Ensley Garza</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>united_states</td>\n      <td>23</td>\n      <td>Lillian Carey</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>united_states</td>\n      <td>21</td>\n      <td>Beau Christensen</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>singapore</td>\n      <td>22</td>\n      <td>Ernesto Gibson</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id   country_name  age     customer_name\n0            1  united_states   22        Kasen Todd\n1            2      singapore   31      Ensley Garza\n2            3  united_states   23     Lillian Carey\n3            4  united_states   21  Beau Christensen\n4            5      singapore   22    Ernesto Gibson"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from datetime import datetime\n\ndf_clean = df_customers.copy()\n\ndf_clean[\"date_of_birth\"] = pd.to_datetime(df_customers['DOB'], format=\"%m/%d/%y\")\ndf_clean.loc[df_clean['date_of_birth'].dt.year >= 2020, 'date_of_birth'] -= pd.DateOffset(years=100)\ndf_clean[\"age\"] = datetime.now().year - df_clean.date_of_birth.dt.year\ndf_clean[\"customer_name\"] = df_clean.first_name + \" \" + df_clean.last_name\ndf_clean.drop([\"last_name\", \"first_name\", \"DOB\", \"city\", \"state\", \"gender\", \"date_of_birth\"], axis=1, inplace=True)\ndf_clean.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>country_name</th>\n      <th>age</th>\n      <th>customer_name</th>\n      <th>is_subscriber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>united_states</td>\n      <td>22</td>\n      <td>Kasen Todd</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>singapore</td>\n      <td>31</td>\n      <td>Ensley Garza</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>united_states</td>\n      <td>23</td>\n      <td>Lillian Carey</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>united_states</td>\n      <td>21</td>\n      <td>Beau Christensen</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>singapore</td>\n      <td>22</td>\n      <td>Ernesto Gibson</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id   country_name  age     customer_name  is_subscriber\n0            1  united_states   22        Kasen Todd              1\n1            2      singapore   31      Ensley Garza              0\n2            3  united_states   23     Lillian Carey              1\n3            4  united_states   21  Beau Christensen              1\n4            5      singapore   22    Ernesto Gibson              1"
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_clean = df_clean.merge(df_churns[[\"customer_id\", \"is_subscriber\"]], how=\"inner\", on=\"customer_id\")\ndf_clean.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": "query = \"\"\"SELECT \n            INVOICE.customer_id, \n            INVOICE.invoice_item_id,\n            INVOICE_ITEM.invoice_item\n            FROM INVOICE\n            INNER JOIN INVOICE_ITEM\n            ON INVOICE.invoice_item_id = INVOICE_ITEM.invoice_item_id;\"\"\"\n\ndf_invoices = pd.DataFrame([row for row in conn.execute(query)], columns=[\"customer_id\", \"invoice_item_id\", \"invoice_item\"])"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "False"
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_invoices.duplicated(subset=[\"customer_id\"]).any()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "`customer_id` doesn't have any duplicates in the invoice dataset."
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>country_name</th>\n      <th>age</th>\n      <th>customer_name</th>\n      <th>is_subscriber</th>\n      <th>subscriber_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>united_states</td>\n      <td>22</td>\n      <td>Kasen Todd</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>singapore</td>\n      <td>31</td>\n      <td>Ensley Garza</td>\n      <td>0</td>\n      <td>aavail_unlimited</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>united_states</td>\n      <td>23</td>\n      <td>Lillian Carey</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>united_states</td>\n      <td>21</td>\n      <td>Beau Christensen</td>\n      <td>1</td>\n      <td>aavail_basic</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>singapore</td>\n      <td>22</td>\n      <td>Ernesto Gibson</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id   country_name  age     customer_name  is_subscriber  \\\n0            1  united_states   22        Kasen Todd              1   \n1            2      singapore   31      Ensley Garza              0   \n2            3  united_states   23     Lillian Carey              1   \n3            4  united_states   21  Beau Christensen              1   \n4            5      singapore   22    Ernesto Gibson              1   \n\n    subscriber_type  \n0    aavail_premium  \n1  aavail_unlimited  \n2    aavail_premium  \n3      aavail_basic  \n4    aavail_premium  "
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_clean = df_clean.merge(df_invoices[[\"customer_id\", \"invoice_item\"]], how=\"inner\", on=\"customer_id\")\ndf_clean.rename(columns={\"invoice_item\":\"subscriber_type\"}, inplace=True)\ndf_clean.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>country_name</th>\n      <th>age</th>\n      <th>customer_name</th>\n      <th>is_subscriber</th>\n      <th>subscriber_type</th>\n      <th>num_streams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>united_states</td>\n      <td>22</td>\n      <td>Kasen Todd</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>singapore</td>\n      <td>31</td>\n      <td>Ensley Garza</td>\n      <td>0</td>\n      <td>aavail_unlimited</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>united_states</td>\n      <td>23</td>\n      <td>Lillian Carey</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>united_states</td>\n      <td>21</td>\n      <td>Beau Christensen</td>\n      <td>1</td>\n      <td>aavail_basic</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>singapore</td>\n      <td>22</td>\n      <td>Ernesto Gibson</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id   country_name  age     customer_name  is_subscriber  \\\n0            1  united_states   22        Kasen Todd              1   \n1            2      singapore   31      Ensley Garza              0   \n2            3  united_states   23     Lillian Carey              1   \n3            4  united_states   21  Beau Christensen              1   \n4            5      singapore   22    Ernesto Gibson              1   \n\n    subscriber_type  num_streams  \n0    aavail_premium           21  \n1  aavail_unlimited           16  \n2    aavail_premium           25  \n3      aavail_basic           18  \n4    aavail_premium           21  "
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_clean = df_clean.merge(df_streams.groupby([\"customer_id\"])[\"stream_id\"].count().reset_index(), how=\"inner\", on=\"customer_id\")\ndf_clean.rename(columns={\"stream_id\":\"num_streams\"}, inplace=True)\ndf_clean.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>is_subscriber</th>\n      <th>num_streams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>500.500000</td>\n      <td>28.034000</td>\n      <td>0.755000</td>\n      <td>19.032000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>288.819436</td>\n      <td>9.114599</td>\n      <td>0.430302</td>\n      <td>4.840497</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>14.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>250.750000</td>\n      <td>22.000000</td>\n      <td>1.000000</td>\n      <td>17.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>500.500000</td>\n      <td>24.000000</td>\n      <td>1.000000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>750.250000</td>\n      <td>34.000000</td>\n      <td>1.000000</td>\n      <td>22.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1000.000000</td>\n      <td>57.000000</td>\n      <td>1.000000</td>\n      <td>30.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "       customer_id          age  is_subscriber  num_streams\ncount  1000.000000  1000.000000    1000.000000  1000.000000\nmean    500.500000    28.034000       0.755000    19.032000\nstd     288.819436     9.114599       0.430302     4.840497\nmin       1.000000    14.000000       0.000000     1.000000\n25%     250.750000    22.000000       1.000000    17.000000\n50%     500.500000    24.000000       1.000000    20.000000\n75%     750.250000    34.000000       1.000000    22.000000\nmax    1000.000000    57.000000       1.000000    30.000000"
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_clean.describe()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## PART 3: Automating the process\n\nTo ensure that you code can be used to automate this process.  First you will save you dataframe or numpy array as a CSV file.  \n\n### QUESTION 5:\n\n**Take the initial steps towards automation**\n\n1. Save your cleaned, combined data as a CSV file.\n2. From the code above create a function or class that performs all of the steps given a database file and a streams CSV file.\n3. Run the function in batches and write a check to ensure you got the same result that you did in the code above.\n\nThere will be some logic involved to ensure that you do not write the same data twice to the target CSV file.\n\nShown below is some code that will split your streams file into two batches. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**1. Save your cleaned, combined data as a CSV file.**"
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": "df_clean.to_csv('../data/aavail-clean.csv', index=False)\n\nfile2cos(project, '/data', 'aavail-clean.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": "## code to split the streams csv into batches\ndf_all = pd.read_csv('../data/aavail-streams.csv')\nhalf = int(round(df_all.shape[0] * 0.5))\ndf_part1 = df_all[:half]\ndf_part2 = df_all[half:]\ndf_part1.to_csv('../data/aavail-streams-1.csv', index=False)\ndf_part2.to_csv('../data/aavail-streams-2.csv', index=False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**2. From the code above create a function or class that performs all of the steps given a database file and a streams CSV file.**"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a script directory to store the scripts for production"
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "...create script directory\n"
                }
            ],
            "source": "def create_script_dir(p, script_path):\n    script_dir = p.project_context.home + script_path\n    if not os.path.exists(script_dir):\n        print(\"...create script directory\")\n        os.makedirs(script_dir)\n    else:\n        print(\"...script directory exists\")\n        \ncreate_script_dir(project, \"/scripts\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "You will need to save your function as a file.  The following cell demonstrates how to do this from within a notebook. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "You will also need to be able to pass the file names to your function without hardcoding them into the script itself.  This is an important step towards automation.  Here are the two libraries commonly used to accomplish this in Python.\n\n* [getopt](https://docs.python.org/3/library/getopt.html)\n* [argparse](https://docs.python.org/3/library/argparse.html)"
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Writing ../scripts/aavail-data-ingestor.py\n"
                }
            ],
            "source": "%%writefile ../scripts/aavail-data-ingestor.py\n#!/usr/bin/env python\n\nimport os\nimport sys\nimport getopt\nimport pandas as pd\nimport numpy as np\nimport sqlite3\nfrom datetime import datetime\n\n\nDATA_DIR = os.path.join(\"..\",\"data\")\n\ndef connect_db(file_path):\n    \"\"\"\n    function to connect to aavail database\n    \"\"\"\n    try:\n        conn = sqlite3.connect(file_path)\n        print(\"...successfully connected to db\\n\")\n    except Error as e:\n        print(\"...unsuccessful connection\\n\",e)\n    \n    return(conn)\n\ndef ingest_db_data(conn):\n    \"\"\"\n    load and clean database data\n    \"\"\"\n    query = \"\"\"SELECT \n            CUSTOMER.customer_id, \n            CUSTOMER.last_name,\n            CUSTOMER.first_name,\n            CUSTOMER.DOB,\n            CUSTOMER.city, \n            CUSTOMER.state, \n            COUNTRY.country_name, \n            CUSTOMER.gender\n            FROM CUSTOMER\n            LEFT JOIN COUNTRY \n            ON CUSTOMER.country_id = COUNTRY.country_id;\"\"\"\n    \n    # execute query and store the results in a pandas dataframe\n    _data = [row for row in conn.execute(query)]\n    columns=[\"customer_id\", \"last_name\", \"first_name\", \"DOB\", \"city\", \"state\", \"country_name\", \"gender\"]\n    df_customers = pd.DataFrame(_data, columns=columns)\n    print(\"...imported db dataset of {} rows and {} columns\".format(df_customers.shape[0], df_customers.shape[1]))\n    \n    # implement checks for quality assurance\n    is_duplicate = df_customers.duplicated(subset=[\"customer_id\"])\n    print(\"...removed {} number of duplicates customer ids\".format(len(df_customers[is_duplicate])))\n    df_customers = df_customers[~is_duplicate].reset_index(drop=True)\n    \n    return df_customers\n\ndef ingest_stream_data(file_path):\n    \"\"\"\n    load and clean stream data\n    \"\"\"\n    # read streams data\n    df_streams = pd.read_csv(file_path)\n    print(\"...imported streams dataset of {} rows and {} columns\".format(df_streams.shape[0], df_streams.shape[1]))\n    \n    # determine customer churn from streams dataset\n    df_churns = df_streams.sort_values([\"customer_id\",\"date\"], ascending=False).groupby([\"customer_id\"]).head(1)\n    df_churns = df_churns.sort_values([\"customer_id\"]).reset_index(drop=True)\n    df_churns[\"is_subscriber\"] = np.where(df_churns.subscription_stopped == 1, 0, 1)\n    \n    # implement checks for quality assurance\n    print(\"...removed {} missing stream ids\".format(df_streams[\"stream_id\"].isna().sum()))\n    is_na = df_streams[\"stream_id\"].isna()\n    df_streams = df_streams[~is_na].reset_index(drop=True)\n    \n    return df_streams, df_churns\n\ndef process_dataframes(df_customers, df_streams, df_churns, conn):\n    \"\"\"\n    combine the data into a single data structure\n    \"\"\"\n    \n    # create a clean copy of the customers dataframe and add new attributes\n    df_clean = df_customers.copy()\n    df_clean[\"date_of_birth\"] = pd.to_datetime(df_customers['DOB'], format=\"%m/%d/%y\")\n    df_clean.loc[df_clean['date_of_birth'].dt.year >= 2020, 'date_of_birth'] -= pd.DateOffset(years=100)\n    df_clean[\"age\"] = datetime.now().year - df_clean.date_of_birth.dt.year\n    df_clean[\"customer_name\"] = df_clean.first_name + \" \" + df_clean.last_name\n    df_clean.drop([\"last_name\", \"first_name\", \"DOB\", \"city\", \"state\", \"gender\", \"date_of_birth\"], axis=1, inplace=True)\n    \n    # ensure we are working with correctly ordered customer_ids df_customers\n    if not np.array_equal(df_clean['customer_id'], df_customers['customer_id']):\n        raise Exception(\"indexes are out of order or unmatched---needs to fix\")\n        \n    df_clean = df_clean.merge(df_churns[[\"customer_id\", \"is_subscriber\"]], how=\"inner\", on=\"customer_id\")\n        \n    # query the db to create a invoice item map\n    query = \"\"\"SELECT \n            INVOICE.customer_id, \n            INVOICE.invoice_item_id,\n            INVOICE_ITEM.invoice_item\n            FROM INVOICE\n            INNER JOIN INVOICE_ITEM\n            ON INVOICE.invoice_item_id = INVOICE_ITEM.invoice_item_id;\"\"\"\n    \n    df_invoices = pd.DataFrame([row for row in conn.execute(query)], columns=[\"customer_id\", \"invoice_item_id\", \"invoice_item\"])\n    \n    # implement checks for quality assurance\n    is_duplicate = df_invoices.duplicated(subset=[\"customer_id\"])\n    if True in is_duplicate:\n        df_invoices = df_invoices[~is_duplicate].reset_index(drop=True)\n        \n    # add new attributes (subscriber_type, num_streams)\n    df_clean = df_clean.merge(df_invoices[[\"customer_id\", \"invoice_item\"]], how=\"inner\", on=\"customer_id\")\n    df_clean.rename(columns={\"invoice_item\":\"subscriber_type\"}, inplace=True)\n    \n    df_clean = df_clean.merge(df_streams.groupby([\"customer_id\"])[\"stream_id\"].count().reset_index(), how=\"inner\", on=\"customer_id\")\n    df_clean.rename(columns={\"stream_id\":\"num_streams\"}, inplace=True)\n    \n    return df_clean\n        \n\ndef update_target(target_file, df_clean, overwrite=False):\n    \"\"\"\n    update line by line in case data are large\n    \"\"\"\n    \n    if overwrite or not os.path.exists(target_file):\n        df_clean.to_csv(target_file, index=False)   \n    else:\n        df_target = pd.read_csv(target_file)\n        df_target.to_csv(target_file, mode='a', index=False)\n        \nif __name__ == \"__main__\":\n  \n    ## collect args\n    arg_string = \"%s -d db_filepath -s streams_filepath\"%sys.argv[0]\n    try:\n        optlist, args = getopt.getopt(sys.argv[1:], 'd:s:')\n    except getopt.GetoptError:\n        print(getopt.GetoptError)\n        raise Exception(arg_string)\n\n    ## handle args\n    streams_file = None\n    db_file = None\n    for o, a in optlist:\n        if o == '-d':\n            db_file = a\n        if o == '-s':\n            streams_file = a\n            \n    streams_file = os.path.join(DATA_DIR, streams_file)\n    db_file = os.path.join(DATA_DIR, db_file)\n    target_file = os.path.join(DATA_DIR, \"aavail-target.csv\")\n    \n    ## make the connection to the database\n    conn = connect_db(db_file)\n\n    ## ingest data base data\n    df_customers = ingest_db_data(conn)\n    df_streams, df_churn = ingest_stream_data(streams_file)\n    df_clean = process_dataframes(df_customers, df_streams, df_churn, conn)\n    \n    ## write\n    update_target(target_file, df_clean, overwrite=False)\n    print(\"done\")\n    "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Save the production script in the IBM database"
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": "file2cos(project, '/scripts', 'aavail-data-ingestor.py')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "You may run the script you just created from the commandline directly or from within this notebook using:"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "...successfully connected to db\n\n...imported db dataset of 1007 rows and 8 columns\n...removed 7 number of duplicates customer ids\n...imported streams dataset of 19032 rows and 4 columns\n...removed 0 missing stream ids\ndone\n"
                }
            ],
            "source": "%run ../scripts/aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams.csv"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "...successfully connected to db\n\n...imported db dataset of 1007 rows and 8 columns\n...removed 7 number of duplicates customer ids\n...imported streams dataset of 19032 rows and 4 columns\n...removed 0 missing stream ids\ndone\n1001 ../data/aavail-target.csv\n"
                }
            ],
            "source": "!rm ../data/aavail-target.csv\n!python ../scripts/aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams.csv\n!wc -l ../data/aavail-target.csv"
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>country_name</th>\n      <th>age</th>\n      <th>customer_name</th>\n      <th>is_subscriber</th>\n      <th>subscriber_type</th>\n      <th>num_streams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>united_states</td>\n      <td>22</td>\n      <td>Kasen Todd</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>singapore</td>\n      <td>31</td>\n      <td>Ensley Garza</td>\n      <td>0</td>\n      <td>aavail_unlimited</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>united_states</td>\n      <td>23</td>\n      <td>Lillian Carey</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>united_states</td>\n      <td>21</td>\n      <td>Beau Christensen</td>\n      <td>1</td>\n      <td>aavail_basic</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>singapore</td>\n      <td>22</td>\n      <td>Ernesto Gibson</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id   country_name  age     customer_name  is_subscriber  \\\n0            1  united_states   22        Kasen Todd              1   \n1            2      singapore   31      Ensley Garza              0   \n2            3  united_states   23     Lillian Carey              1   \n3            4  united_states   21  Beau Christensen              1   \n4            5      singapore   22    Ernesto Gibson              1   \n\n    subscriber_type  num_streams  \n0    aavail_premium           21  \n1  aavail_unlimited           16  \n2    aavail_premium           25  \n3      aavail_basic           18  \n4    aavail_premium           21  "
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_clean_all = pd.read_csv(\"../data/aavail-target.csv\")\ndf_clean_all.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Run the script once for each batch that you created and then load both the original and batch versions back into the notebook to check that they are the same. "
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "...successfully connected to db\n\n...imported db dataset of 1007 rows and 8 columns\n...removed 7 number of duplicates customer ids\n...imported streams dataset of 9516 rows and 4 columns\n...removed 0 missing stream ids\ndone\n498 ../data/aavail-target.csv\n"
                }
            ],
            "source": "!rm ../data/aavail-target.csv\n!python ../scripts/aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams-1.csv\n!wc -l ../data/aavail-target.csv"
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>country_name</th>\n      <th>age</th>\n      <th>customer_name</th>\n      <th>is_subscriber</th>\n      <th>subscriber_type</th>\n      <th>num_streams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>united_states</td>\n      <td>22</td>\n      <td>Kasen Todd</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>singapore</td>\n      <td>31</td>\n      <td>Ensley Garza</td>\n      <td>0</td>\n      <td>aavail_unlimited</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>united_states</td>\n      <td>23</td>\n      <td>Lillian Carey</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>united_states</td>\n      <td>21</td>\n      <td>Beau Christensen</td>\n      <td>1</td>\n      <td>aavail_basic</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>singapore</td>\n      <td>22</td>\n      <td>Ernesto Gibson</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id   country_name  age     customer_name  is_subscriber  \\\n0            1  united_states   22        Kasen Todd              1   \n1            2      singapore   31      Ensley Garza              0   \n2            3  united_states   23     Lillian Carey              1   \n3            4  united_states   21  Beau Christensen              1   \n4            5      singapore   22    Ernesto Gibson              1   \n\n    subscriber_type  num_streams  \n0    aavail_premium           21  \n1  aavail_unlimited           16  \n2    aavail_premium           25  \n3      aavail_basic           18  \n4    aavail_premium           21  "
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_clean_b1 = pd.read_csv(\"../data/aavail-target.csv\")\ndf_clean_b1.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "...successfully connected to db\n\n...imported db dataset of 1007 rows and 8 columns\n...removed 7 number of duplicates customer ids\n...imported streams dataset of 9516 rows and 4 columns\n...removed 0 missing stream ids\ndone\n505 ../data/aavail-target.csv\n"
                }
            ],
            "source": "!rm ../data/aavail-target.csv\n!python ../scripts/aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams-2.csv\n!wc -l ../data/aavail-target.csv"
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>country_name</th>\n      <th>age</th>\n      <th>customer_name</th>\n      <th>is_subscriber</th>\n      <th>subscriber_type</th>\n      <th>num_streams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>497</td>\n      <td>united_states</td>\n      <td>17</td>\n      <td>Deacon Porter</td>\n      <td>1</td>\n      <td>aavail_unlimited</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>498</td>\n      <td>singapore</td>\n      <td>18</td>\n      <td>Romeo Campbell</td>\n      <td>0</td>\n      <td>aavail_basic</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>499</td>\n      <td>united_states</td>\n      <td>28</td>\n      <td>Eloise Hendricks</td>\n      <td>0</td>\n      <td>aavail_premium</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500</td>\n      <td>united_states</td>\n      <td>21</td>\n      <td>Hayley Harrell</td>\n      <td>1</td>\n      <td>aavail_unlimited</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>501</td>\n      <td>united_states</td>\n      <td>23</td>\n      <td>Madelynn Conley</td>\n      <td>1</td>\n      <td>aavail_premium</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   customer_id   country_name  age     customer_name  is_subscriber  \\\n0          497  united_states   17     Deacon Porter              1   \n1          498      singapore   18    Romeo Campbell              0   \n2          499  united_states   28  Eloise Hendricks              0   \n3          500  united_states   21    Hayley Harrell              1   \n4          501  united_states   23   Madelynn Conley              1   \n\n    subscriber_type  num_streams  \n0  aavail_unlimited            7  \n1      aavail_basic            1  \n2    aavail_premium            6  \n3  aavail_unlimited           21  \n4    aavail_premium            4  "
                    },
                    "execution_count": 44,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_clean_b2 = pd.read_csv(\"../data/aavail-target.csv\")\ndf_clean_b2.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### QUESTION 6:\n\n**How can you improve the process?**\n\nIn paragraph form or using bullets write down some of the ways that you could improve this pipeline."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "YOUR ANSWER HERE\n\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "* How do we ensure that the batches after concatenate do not generate duplicates?\n* Batches should be created in the final, combined, cleaned dataset.\n* I would add also some logical tests to assure the quality of the dataset, for example data type\n* Kudos to the automation/productionize part\n* Quality controls added to ensure that the DOB has been successfully converted\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}