{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## CASE STUDY - Deploying a recommender\n\nWe have seen the movie lens data on a toy dataset now lets try something a little bigger.  You have some\nchoices.\n\n* [MovieLens Downloads](https://grouplens.org/datasets/movielens/latest/)\n\nIf your resources are limited (your working on a computer with limited amount of memory)\n\n> continue to use the sample_movielens_ranting.csv\n\nIf you have a computer with at least 8GB of RAM\n\n> download the ml-latest-small.zip\n\nIf you have the computational resources (access to Spark cluster or high-memory machine)\n\n> download the ml-latest.zip\n\nThe two important pages for documentation are below.\n\n* [Spark MLlib collaborative filtering docs](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) \n* [Spark ALS docs](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "import os\nimport shutil\nimport pandas as pd\nimport numpy as np\nimport pyspark as ps\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import DoubleType"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "2.4.5\n"
                }
            ],
            "source": "## ensure the spark context is available\nspark = (ps.sql.SparkSession.builder\n        .appName(\"sandbox\")\n        .getOrCreate()\n        )\n\nsc = spark.sparkContext\nprint(spark.version) "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Ensure the data are downloaded and specify the file paths here\n"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "data_dir = os.path.join(\".\", \"data\")\nratings_file = os.path.join(data_dir, \"ratings.csv\")\nmovies_file = os.path.join(data_dir, \"movies.csv\")"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+------+-------+------+---------+\n|userId|movieId|rating|timestamp|\n+------+-------+------+---------+\n|     1|      1|   4.0|964982703|\n|     1|      3|   4.0|964981247|\n|     1|      6|   4.0|964982224|\n|     1|     47|   5.0|964983815|\n+------+-------+------+---------+\nonly showing top 4 rows\n\n+-------+--------------------+--------------------+\n|movieId|               title|              genres|\n+-------+--------------------+--------------------+\n|      1|    Toy Story (1995)|Adventure|Animati...|\n|      2|      Jumanji (1995)|Adventure|Childre...|\n|      3|Grumpier Old Men ...|      Comedy|Romance|\n|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n+-------+--------------------+--------------------+\nonly showing top 4 rows\n\n"
                }
            ],
            "source": "# Load the data\nratings = spark.read.csv(ratings_file, header=True, inferSchema=True)\nmovies = spark.read.csv(movies_file, header=True, inferSchema=True)\n\nratings.show(n=4)\nmovies.show(n=4)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## QUESTION 1\n\nExplore the movie lens data a little and summarize it"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+-------+------------------+----------------+------------------+--------------------+\n|summary|           user_id|        movie_id|            rating|           timestamp|\n+-------+------------------+----------------+------------------+--------------------+\n|  count|            100836|          100836|            100836|              100836|\n|   mean|326.12756356856676|19435.2957177992| 3.501556983616962|1.2059460873684695E9|\n| stddev| 182.6184914635004|35530.9871987003|1.0425292390606342|2.1626103599513078E8|\n|    min|                 1|               1|               0.5|           828124615|\n|    max|               610|          193609|               5.0|          1537799250|\n+-------+------------------+----------------+------------------+--------------------+\n\nUnique users 610\nUnique movies 9724\nMovies with Rating > 2: 8852\nMovies with Rating > 3: 7363\nMovies with Rating > 4: 4056\n"
                }
            ],
            "source": "## (summarize the data)\n\n## rename columns\nratings = ratings.withColumnRenamed(\"movieID\", \"movie_id\")\nratings = ratings.withColumnRenamed(\"userID\", \"user_id\")\n\nratings.describe().show()\n\nprint(\"Unique users {}\".format(ratings.select(\"user_id\").distinct().count()))\nprint(\"Unique movies {}\".format(ratings.select(\"movie_id\").distinct().count()))\nprint('Movies with Rating > 2: {}'.format(ratings.filter('rating > 2').select('movie_id').distinct().count()))\nprint('Movies with Rating > 3: {}'.format(ratings.filter('rating > 3').select('movie_id').distinct().count()))\nprint('Movies with Rating > 4: {}'.format(ratings.filter('rating > 4').select('movie_id').distinct().count()))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## QUESTION 2\n\nFind the ten most popular movies---that is the then movies with the highest average rating\n\n>Hint: you may want to subset the movie matrix to only consider movies with a minimum number of ratings"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>count</th>\n      <th>avg(rating)</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>318</td>\n      <td>317</td>\n      <td>4.429022</td>\n      <td>Shawshank Redemption, The (1994)</td>\n      <td>Crime|Drama</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>858</td>\n      <td>192</td>\n      <td>4.289062</td>\n      <td>Godfather, The (1972)</td>\n      <td>Crime|Drama</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2959</td>\n      <td>218</td>\n      <td>4.272936</td>\n      <td>Fight Club (1999)</td>\n      <td>Action|Crime|Drama|Thriller</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1221</td>\n      <td>129</td>\n      <td>4.259690</td>\n      <td>Godfather: Part II, The (1974)</td>\n      <td>Crime|Drama</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48516</td>\n      <td>107</td>\n      <td>4.252336</td>\n      <td>Departed, The (2006)</td>\n      <td>Crime|Drama|Thriller</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1213</td>\n      <td>126</td>\n      <td>4.250000</td>\n      <td>Goodfellas (1990)</td>\n      <td>Crime|Drama</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>58559</td>\n      <td>149</td>\n      <td>4.238255</td>\n      <td>Dark Knight, The (2008)</td>\n      <td>Action|Crime|Drama|IMAX</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>50</td>\n      <td>204</td>\n      <td>4.237745</td>\n      <td>Usual Suspects, The (1995)</td>\n      <td>Crime|Mystery|Thriller</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1197</td>\n      <td>142</td>\n      <td>4.232394</td>\n      <td>Princess Bride, The (1987)</td>\n      <td>Action|Adventure|Comedy|Fantasy|Romance</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>260</td>\n      <td>251</td>\n      <td>4.231076</td>\n      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n      <td>Action|Adventure|Sci-Fi</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   movie_id  count  avg(rating)                                      title  \\\n0       318    317     4.429022           Shawshank Redemption, The (1994)   \n1       858    192     4.289062                      Godfather, The (1972)   \n2      2959    218     4.272936                          Fight Club (1999)   \n3      1221    129     4.259690             Godfather: Part II, The (1974)   \n4     48516    107     4.252336                       Departed, The (2006)   \n5      1213    126     4.250000                          Goodfellas (1990)   \n6     58559    149     4.238255                    Dark Knight, The (2008)   \n7        50    204     4.237745                 Usual Suspects, The (1995)   \n8      1197    142     4.232394                 Princess Bride, The (1987)   \n9       260    251     4.231076  Star Wars: Episode IV - A New Hope (1977)   \n\n                                    genres  \n0                              Crime|Drama  \n1                              Crime|Drama  \n2              Action|Crime|Drama|Thriller  \n3                              Crime|Drama  \n4                     Crime|Drama|Thriller  \n5                              Crime|Drama  \n6                  Action|Crime|Drama|IMAX  \n7                   Crime|Mystery|Thriller  \n8  Action|Adventure|Comedy|Fantasy|Romance  \n9                  Action|Adventure|Sci-Fi  "
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "## Group movies\nmovies_counts = ratings.groupBy(\"movie_id\").count()\nmovies_rating = ratings.groupBy(\"movie_id\").avg(\"rating\")\nmovies_rating_and_count = movies_counts.join(movies_rating, \"movie_id\")\n\n## Consider movies with more than 100 views\nthreshold = 100\ntop_movies =  movies_rating_and_count.filter(\"count > 100\").orderBy(\"avg(rating)\", ascending=False)\n\n## Add the movie titles to data frame\nmovies = movies.withColumnRenamed(\"movieID\", \"movie_id\")\ntop_movies = top_movies.join(movies, \"movie_id\")\n\ntop_movies.toPandas().head(10)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## QUESTION 3\n\nCompare at least 5 different values for the ``regParam``\n\nUse the `` ALS.trainImplicit()`` and compare it to the ``.fit()`` method.  See the [Spark ALS docs](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS)\nfor example usage. "
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "regParam=0.01, RMSE=1.08\nregParam=0.05, RMSE=0.95\nregParam=0.1, RMSE=0.89\nregParam=0.15, RMSE=0.88\nregParam=0.25, RMSE=0.91\n"
                }
            ],
            "source": "## split the data set to  train and test set\n\n(train, test) = ratings.randomSplit([0.8, 0.2])\n\n## Create a function to train the model\ndef train_model(reg_param, implicit_prefs=False):\n    als = ALS(maxIter=5, regParam=reg_param, userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\", implicitPrefs=implicit_prefs)\n    model = als.fit(train)\n\n    predictions = model.transform(test)\n    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n\n    rmse = evaluator.evaluate(predictions)\n    print(\"regParam={}, RMSE={}\".format(reg_param, np.round(rmse,2)))\n    \n\nfor reg_param in [0.01, 0.05, 0.1, 0.15, 0.25]:\n    train_model(reg_param)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## QUESTION 4\n\nWith your best `regParam` try using the `implicitPrefs` flag."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "regParam=0.1, RMSE=3.24\n"
                }
            ],
            "source": "train_model(reg_param=0.1, implicit_prefs=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## QUESTION 5\n\nUse model persistence to save your finalized model"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "...training\n...overwritting saved model\n...saving top-movies\ndone.\n"
                }
            ],
            "source": "## re-train using the whole data set\nprint(\"...training\")\nals = ALS(maxIter=5, regParam=0.1, userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\nmodel = als.fit(ratings)\n\n## save the model for furture use\nsave_dir = \"./models/saved-recommender\"\nif os.path.isdir(save_dir):\n    print(\"...overwritting saved model\")\n    shutil.rmtree(save_dir)\n\n## save the top-ten movies\nprint(\"...saving top-movies\")\ntop_movies.toPandas().head(10).to_csv(\"./data/top-movies.csv\", index=False)\n    \n## save model\nmodel.save(save_dir)\nprint(\"done.\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## QUESTION 6\n\nUse ``spark-submit`` to load the model and demonstrate that you can load the model and interface with it."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.recommendation import ALSModel\nfrom_saved_model = ALSModel.load(save_dir)"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[Row(user_id=1, movie_id=5, prediction=3.4502124786376953), Row(user_id=1, movie_id=10, prediction=3.862915515899658), Row(user_id=2, movie_id=1, prediction=3.4418039321899414)]\n"
                }
            ],
            "source": "test = spark.createDataFrame([(1, 5), (1, 10), (2, 1)], [\"user_id\", \"movie_id\"])\npredictions = sorted(model.transform(test).collect(), key=lambda r: r[0])\nprint(predictions)"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Overwriting ./scripts/case-study-spark-submit.sh\n"
                }
            ],
            "source": "%%writefile ./scripts/case-study-spark-submit.sh\n\n#!/bin/bash\n${SPARK_HOME}/bin/spark-submit \\\n--master local[4] \\\n--executor-memory 1G \\\n--driver-memory 1G \\\n$@"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "!chmod 711 ./scripts/case-study-spark-submit.sh"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "20/04/25 13:02:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n20/04/25 13:02:14 INFO SparkContext: Running Spark version 2.4.5\n20/04/25 13:02:14 INFO SparkContext: Submitted application: recommend\n20/04/25 13:02:14 INFO SecurityManager: Changing view acls to: jovyan\n20/04/25 13:02:14 INFO SecurityManager: Changing modify acls to: jovyan\n20/04/25 13:02:14 INFO SecurityManager: Changing view acls groups to: \n20/04/25 13:02:14 INFO SecurityManager: Changing modify acls groups to: \n20/04/25 13:02:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jovyan); groups with view permissions: Set(); users  with modify permissions: Set(jovyan); groups with modify permissions: Set()\n20/04/25 13:02:15 INFO Utils: Successfully started service 'sparkDriver' on port 34689.\n20/04/25 13:02:15 INFO SparkEnv: Registering MapOutputTracker\n20/04/25 13:02:15 INFO SparkEnv: Registering BlockManagerMaster\n20/04/25 13:02:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n20/04/25 13:02:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n20/04/25 13:02:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b9fec6ff-2600-4cf4-8096-5e5f7d49258b\n20/04/25 13:02:15 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\n20/04/25 13:02:15 INFO SparkEnv: Registering OutputCommitCoordinator\n20/04/25 13:02:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n20/04/25 13:02:15 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n20/04/25 13:02:15 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://9278b248e903:4041\n20/04/25 13:02:15 INFO Executor: Starting executor ID driver on host localhost\n20/04/25 13:02:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45693.\n20/04/25 13:02:16 INFO NettyBlockTransferService: Server created on 9278b248e903:45693\n20/04/25 13:02:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n20/04/25 13:02:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 9278b248e903, 45693, None)\n20/04/25 13:02:16 INFO BlockManagerMasterEndpoint: Registering block manager 9278b248e903:45693 with 366.3 MB RAM, BlockManagerId(driver, 9278b248e903, 45693, None)\n20/04/25 13:02:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 9278b248e903, 45693, None)\n20/04/25 13:02:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 9278b248e903, 45693, None)\n20/04/25 13:02:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/jovyan/work/spark-warehouse').\n20/04/25 13:02:16 INFO SharedState: Warehouse path is 'file:/home/jovyan/work/spark-warehouse'.\n20/04/25 13:02:17 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\nbest rated [(260,), (2628,), (1196,), (122886,), (187595,), (179819,), (1210,)]\n20/04/25 13:02:28 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n20/04/25 13:02:28 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\nclosest_users\n [(53,), (543,), (276,), (452,), (93,), (371,), (523,), (43,), (475,), (12,), (1,), (327,), (30,), (527,), (122,), (441,), (25,), (389,), (515,), (348,), (106,), (246,), (340,), (562,), (519,), (48,), (99,), (154,), (243,), (594,), (453,), (586,), (267,), (169,), (553,), (486,), (201,), (435,), (52,), (538,), (45,), (337,), (186,), (336,), (80,), (171,), (69,), (46,), (408,), (450,), (578,), (601,), (417,), (97,), (250,), (37,), (284,), (447,), (573,), (569,), (236,), (258,), (251,), (108,), (585,), (355,), (319,), (540,), (234,), (62,), (210,), (574,), (240,), (491,), (592,), (413,), (533,), (388,), (197,), (537,), (498,), (558,), (556,), (495,), (119,), (595,), (40,), (95,), (375,), (273,), (568,), (382,), (13,), (362,), (400,), (164,), (72,), (66,), (162,), (429,), (220,), (92,), (304,), (579,), (548,), (544,), (472,), (291,), (539,), (367,), (484,), (492,), (256,), (200,), (591,), (224,), (582,), (213,), (383,), (209,), (597,), (547,), (398,), (451,), (35,), (421,), (88,), (505,), (302,), (275,), (79,), (380,), (178,), (278,), (335,), (360,), (555,), (459,), (554,), (34,), (344,), (58,), (192,), (176,), (2,), (482,), (56,), (71,), (466,), (557,), (580,), (225,), (572,), (532,), (112,), (409,), (502,), (494,), (32,), (259,), (252,), (511,), (55,), (598,), (147,), (73,), (51,), (393,), (282,), (607,), (392,), (477,), (546,), (261,), (98,), (352,), (584,), (136,), (205,), (456,), (534,), (11,), (174,), (269,), (518,), (402,), (280,), (239,), (575,), (549,), (345,), (364,), (111,), (155,), (77,), (564,), (100,), (257,), (531,), (67,), (255,), (21,), (542,), (151,), (188,), (116,), (551,), (587,), (550,), (499,), (347,), (376,), (82,)]\n"
                }
            ],
            "source": "! ./scripts/case-study-spark-submit.sh ./scripts/recommender-submit.py"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}